# DCSIDuniverse
In business development, a large number of scenarios need unique ID for identification: users need unique ID, commodities need unique ID, messages need unique ID, events need unique ID, etc., all need global unique ID, especially in complex distributed business scenarios, the unique ID of the whole bureau is more important.    So what are the features or requirements of distributed unique IDs?  ① Uniqueness: the generated ID is globally unique, and the conflict probability is minimal in a specific range.  ② Orderliness: the generated IDs are ordered according to some rules, which is convenient for database insertion and sorting.  ③ Availability: it can guarantee the high availability and the right ID generation at any time.  ④ Autonomy: in distributed environment, ID can be generated by itself without relying on central authentication.  ⑤ Security: do not expose system and business information, such as: number of orders, number of users, etc.    What are the methods for generating distributed unique IDs?  Generally speaking, there are three kinds of methods: database self increment ID, UUID generation, snowflake snowflake algorithm
The following are the three categories and their optimization schemes
1、 Database auto increment ID
Core idea: use the database ID self increment strategy (such as MySQL Auto_ increment）。
advantage:
① Simple, natural and orderly.
Disadvantages:
① Concurrency is not good.
② Database write pressure is high.
③ The database cannot be used after failure.
④ There is a risk of quantity leakage.
In view of the above shortcomings, there are several optimization schemes as follows:
1. Split the database horizontally, set different initial values and the same auto increment step size
The core idea is to split the database horizontally, and set different initial values and the same auto increment step size for each database.
Database horizontal split
As shown in the figure, it can ensure that the ID generated by each database does not conflict, but this fixed step size method will also lead to the problem of capacity expansion. It is easy to think that there will be a dilemma that there is no initial value of ID separable when expanding the capacity. The solutions are:
① The step size is determined according to the consideration of capacity expansion.
② Add other bit marks to distinguish expansion.
This is actually a trade-off between requirements and solutions, and the most appropriate way is selected according to the requirements.
2. Batch cache auto increment ID
Core idea: if a single machine is used for ID generation, the capacity expansion problem caused by fixed step size can be avoided (the disadvantage of scheme 1).
The specific approach is: each batch of ID to different machines to slowly consume, so that the pressure of the database will be reduced to one in N, and the failure can persist for a period of time.  
Batch cache auto increment ID
As shown in the figure, but the disadvantage of this method is that the server restarts and a single point of failure will cause the ID discontinuity.
There is no best plan, only the most suitable one.
3. Redis generates ID
Core idea: all command operations of redis are single threaded. It provides self adding atomic commands such as incr and increby, so it can ensure that the generated ID is unique and orderly.
advantage:
① It is not dependent on database, flexible and convenient, and its performance is better than that of database.
② The digital ID is sorted naturally, which is helpful for paging or sorting results.
Disadvantages:
① If there is no redis in the system, new components need to be introduced to increase the system complexity.
② There is a lot of work to code and configure.
Optimization scheme:
Considering the performance bottleneck of a single node, redis cluster can be used to obtain higher throughput, and the above scheme (1) horizontal database splitting, setting different initial values and the same step size; 2) batch cache auto increment ID, is used to configure the cluster.
PS: it is more suitable to use redis to generate serial numbers starting from 0 every day. For example, "order number = date + current day self growth number", a key can be generated in redis every day and accumulated by incr.
2、 UUID generation
The core idea: the UUID is generated by combining the network card of the machine (based on the hash value MD5 / SHA1 of the namespace / name), the local time (based on the timestamp &amp; clock sequence) and a random number.
Its structure is as follows:

For example: 550e8400-e29b-41d4-a716-446655440000
advantage:
① Local generation, no network consumption, simple generation, no high availability risk.
Disadvantages:
① Not easy to store: UUID is too long, 16 bytes, 128 bits, usually expressed as a 36 length string, many scenarios are not applicable.
② Information insecurity: the algorithm of generating UUID based on MAC address may cause MAC address disclosure, which was used to find the location of Melissa virus.
③ Low efficiency of unordered query: the generated UUID is an unordered unreadable string, so its query efficiency is low.
Up to now, there are five ways to generate UUID in the industry
① Version 1 - time based UUID (date time &amp; MAC address)
Rule: it mainly depends on the current timestamp and MAC address of the machine, so it can guarantee the global uniqueness.
Advantages: it can basically guarantee the global uniqueness.
Disadvantages: MAC address is used, so MAC address and generation time are exposed.
② Version 2 - UUID (date time &amp; group / user ID) for distributed security:
Rule: replace the first four digits of the timestamp of version 1 with the uid or GID of POSIX, which is rarely used.
Advantages: it can guarantee global uniqueness.
Disadvantages: rarely used, common library is not implemented.
③ Version 3 - name space based uuid-md5 (MD5 hash &amp; namespace)
Rule: generate MD5 hash value based on the specified namespace / name, which is not recommended by the standard.
Advantages: UUIDs under different name spaces or names are unique; UUIDs obtained under the same name space and name remain repeated.
Disadvantages: MD5 collision problem, only used for backward compatibility, no longer used in the future.
④ Version 4 - UUID (pseudo random number) based on random numbers:
Rules: generated based on random or pseudo-random numbers.
Advantages: easy to implement.
Disadvantages: the repetition rate can be calculated. The probability is also related to the quality of the random number generator. In order to avoid the increase of repetition probability, we must use the strong pseudo-random number generator based on cryptography to generate values.
⑤ Version 5 - namespace based uuid-sha1 Version (SHA-1 hash &amp; namespace):
Rule: change version 3 hash algorithm to SHA1.
Advantages: UUIDs under different name spaces or names are unique; UUIDs obtained under the same name space and name remain repeated.
Disadvantages: SHA1 calculation is relatively time-consuming.

Generally speaking:
① Version 1 / 2 is suitable for scenarios that require a high degree of uniqueness and no repetition.
② Version 3 / 5 is suitable for environments that are unique within a certain range and need or may generate UUID repeatedly.
③ Version 4 is suitable for scenarios where the uniqueness requirement is not strict and the pursuit of simplicity is pursued.
The related pseudocodes are as follows:
Refer to CSDN blog for detailed code
3、 Snowflake algorithm
The core idea: divide 64 bit into multiple segments to mark the machine, time and some concurrent sequence separately, so that the IDs generated by each machine and the same machine are different from each other.
PS: this structure is a division of twitter, the proposer of snowflake algorithm. But in fact, the algorithm can be used flexibly. According to the concurrency of its own business, machine distribution, service life, etc., it can freely determine the number of bits of each part, so as to increase or decrease the order of a certain part. For example: Baidu's uidgenerator, meituan's leaf, etc., are based on snowflake algorithm to do some changes suitable for their own business.
Here are several different optimization schemes of snowflake algorithm
1. Twitter's snowflake algorithm
The core idea is: using bigint (64bit) as the ID generation type, and dividing the 64bit into multiple segments.
Its structure is as follows:
Twitter's snowflake structure
The meaning of each field in snowflake
explain:
① 1-bit identifier: since the long basic type is signed in Java, the highest bit is the sign bit, the positive number is 0, and the negative number is 1, so the ID is generally positive, and the highest bit is 0.
② 41 bit time cut (millisecond level): it should be noted that the 41 bit time cut is not the time cut of storing the current time, but the value obtained by the difference of the storage time section (current time section - start time section). The start time cut here generally refers to the time cut used by our ID generator, which is specified by our program. A 41 bit millisecond cut-off can be used for 69 years (i.e. t = (1L < 41) / (1000 * 60 * 60 * 24 * 365) = 69).
③ 10 bit data machine bit: including 5-bit data center ID (datacenter ID) and 5-bit machine ID (workerid). Up to 1024 nodes can be deployed (i.e. 1 < < 10 = 1024). Beyond this number, the generated IDs may conflict.
④ 12 bit sequence: counting in milliseconds. The 12 bit counting sequence number supports each node to generate 4096 ID serial numbers per millisecond (the same machine, the same time section) (i.e. 1 < < 12 = 4096).
PS: all the structural identifiers (1 + 41 + 10 + 12 = 64) add up to exactly 64 bits, which is just a long type.
advantage:
① In general, the performance increases with the time trend, and the performance is better when the index tree is inserted later.
② There is no ID collision in the whole distributed system (distinguished by data center ID and machine ID).
③ Therefore, it does not rely on the third-party database (about 260000) and can generate no third-party database.
Disadvantages:
① Because snowflake algorithm is strongly dependent on time, in the distributed environment, if clock callback occurs, it is likely to cause ID duplication, ID disorder, and service will be in an unavailable state.
The solutions are:
a. Give ID generation to a small number of servers and turn off clock synchronization.
b. Report the error directly and hand it to the upper layer for business processing.
c. If the callback time is short and within the time requirement, such as 5ms, then wait for the callback time to generate.
d. If the callback time is too long, you can't wait. You can spare a small number of bits (1-2 bits) as the callback bits. Once the clock is called back, add 1 to the callback bit to get a different ID. the 2-bit callback bit is allowed to mark 3 times of clock call back, which is basically enough. If it exceeds, you can choose to throw an exception.
Refer to CSDN blog for detailed code
2. Mongo's objectid algorithm
The core idea is: use 12 byte (24bit) bson type string as ID, and divide the 24bit into multiple segments.
explain:
① 4-byte (8-bit) timestamp: Unix timestamp (accurate to seconds).
② 3-byte (6-bit) machine: the unique identifier of the host (usually a hash value of the machine host name).
③ 2-byte (4-bit) PID: process identifier for different processes of the same machine to generate objectid.
④ 3-byte (6-bit) increment: an automatically incremented value generated by a counter starting with a random number. It is used to ensure that the objectid generated in the same second will not find conflicts, allowing the uniqueness of 256 ^ 3 (16777216) records.
For example, the objectid format is 5dba76a3-d2c366-7f99-57dfb0
① Timestamp: 5dba76a3 (corresponding to decimal: 1572501155).
② Machine: d2c366 (corresponding to decimal: 13812582).
③ PID: 7f99 (corresponding to decimal system: 32665).
④ Increment: 57dfb0 (corresponding to decimal: 5758896).
advantage:
① Local generation, no network consumption, simple generation, no high availability risk.
② The generated ID contains time information, which can be extracted.   
Disadvantages:
① Not easy to store: 12 byte 24 bit string representation, many scenarios are not applicable.
In the new objectid, "machine identification code + process number" is changed to use random number as the value of machine identification and process number
Mark: since mongodb 3.4 (the earliest released in December 2016), the design of objectid has been modified. The middle 5-byte value is changed from the original "machine identification code + process number" to the random number as the value of machine identification and process number.


The question is, why not continue to use "machine ID + process number"?
The problem is that in this era when physical machines are rare and virtual machines, virtual machines and containers are rampant, the machine identification and process number are not reliable.
① Machine identification code:
The machine identification code of objectid is the first few bits of the hash value of system hostname. So, the problem comes. How many virtual machines are prepared, and the host name is the default localhost. Who wants to use this thing? Do you have to deliberately give different hostnames to different machines? In addition, the default value of hostname in container and virtual machine is random number, and it will not check whether there is a duplicate name of hostname in the same cluster.
② Process number:
This problem is even bigger. You should know that the process in the container has its own independent process space. In this space, it only uses its own process (and its subprocesses), so its process number is always 1. In other words, if a service (either a Mongo instance or a Mongo client) is deployed using a container, no matter how many instances are deployed, the eighth and ninth byte of the objectid generated on the service is always 0000 0001, which means that these two bytes are obsolete.
To sum up, instead of using a fixed value to "distinguish different process instances", and the fixed value is still a randomly set or randomly generated hostname plus a process number that may always be 1, it is better to randomly generate a new value each time.
It can be seen that this is an architectural change at the platform level that has affected the design scheme at the application level. With the continuous development of cloud and container, such a story will continue to be staged.
1) Old version: use hash value of host name for machine, use process identifier as PID
Refer to CSDN blog for detailed code
2) Use the new version of PID as a random number
Refer to CSDN blog for detailed code
3. Baidu uidgenerator algorithm
Uidgenerator is Baidu's open-source distributed ID generator, which is based on the implementation of the snowflake algorithm. It seems that it is OK, but it needs the help of the database, and the configuration is more complex.
For details, please refer to the official website: https://github.com/baidu/uid-generator/blob/master/README.zh_ cn.md
4. Meituan leaf algorithm
Leaf is an open-source distributed ID generator of meituan, which can ensure global uniqueness, increasing trend, monotonous increase and information security. It also mentions the comparison of several distributed solutions, but it also needs to rely on middleware such as relational database and zookeeper.
For details, please refer to the official website: https://tech.meituan.com/2017/04/21/mt-leaf.html
Summary
This article shares several common solutions of global ID generation service, and compares their advantages and disadvantages and applicable scenarios. In practical work, we can combine our own business and system architecture system for reasonable selection.
